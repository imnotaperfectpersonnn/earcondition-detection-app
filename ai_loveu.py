# -*- coding: utf-8 -*-
"""Ai-love-u.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZtJ_X0_AE5EEG-8RUCNwYFE013HAuoL3
"""

import streamlit as st
from PIL import Image
import tempfile
import os

blue_overlay = """
<style>
.stApp {
  background: linear-gradient(120deg, #89f7fe, #66a6ff);
  min-height: 100vh;
}
.stApp .main {
  background-color: rgba(255, 255, 255, 0.65);
  backdrop-filter: blur(8px);
  margin: 2rem;
  padding: 2rem;
  border-radius: 20px;
  box-shadow: 0 4px 25px rgba(0,0,0,0.15);
}
</style>
"""

st.markdown(blue_overlay, unsafe_allow_html=True)
st.set_page_config(page_title="Automated Ear Disease Detection", layout="wide")

st.title("Automated Ear Disease Detection through Object Detection of Otoscopic Images")

col1, col2 = st.columns([1, 2])

with col1:
    st.header("Inputs")
    uploaded_image = st.file_uploader("Upload an otoscopic image", type=["png", "jpg", "jpeg"])
    # Allow user to optionally upload a model, but default will try to use ./best.pt
    model_file = st.file_uploader("Upload a model file (.pt) — optional", type=["pt", "onnx", "yaml"])
    conf = st.slider("Confidence threshold", 0.0, 1.0, 0.25, 0.01)
    run = st.button("Run inference")

with col2:
    st.header("Preview / Result")
    if uploaded_image is None:
        st.info("Upload an otoscopic image to begin analysis.")
    else:
        img = Image.open(uploaded_image).convert("RGB")
        st.image(img, caption="Input image", use_column_width=True)
        if not run:
            st.caption("Click **Run inference** to detect possible ear conditions.")

def load_ultralytics_model_from_path(path):
    try:
        from ultralytics import YOLO
        model = YOLO(path)
        return model
    except Exception as e:
        st.warning(f"Could not load Ultralytics model: {e}")
        return None

def dummy_inference_pil(image_pil):
    import PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont
    im = image_pil.copy()
    draw = ImageDraw.Draw(im)
    w, h = im.size
    box = (int(w*0.15), int(h*0.15), int(w*0.75), int(h*0.75))
    draw.rectangle(box, outline="red", width=6)
    try:
        font = ImageFont.truetype("DejaVuSans.ttf", size=20)
    except:
        font = ImageFont.load_default()
    draw.text((box[0], box[1]-24), "possible_condition:0.99", fill="red", font=font)
    return im

if run:
    if uploaded_image is None:
        st.error("Please upload an image first.")
    else:
        # save uploaded image to temp file
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=".jpg")
        tfile.write(uploaded_image.getbuffer())
        tfile.flush()
        tfile.close()

        # Determine model path: uploaded model overrides local best.pt
        model = None
        model_path = None
        if model_file is not None:
            model_path = os.path.join(tempfile.gettempdir(), model_file.name)
            with open(model_path, "wb") as f:
                f.write(model_file.getbuffer())
        else:
            local_path = os.path.join(os.getcwd(), "best.pt")
            if os.path.exists(local_path):
                model_path = local_path

        if model_path is not None:
            model = load_ultralytics_model_from_path(model_path)

        result_image = None
        if model is not None:
            st.info("Running inference with provided model...")
            try:
                results = model.predict(source=tfile.name, conf=conf, save=False, verbose=False)
                r = results[0]
                try:
                    annotated = r.plot()
                    import numpy as np
                    annotated_pil = Image.fromarray(annotated)
                    result_image = annotated_pil
                except Exception as ex:
                    st.warning(f"Could not plot results: {ex}")
                    # fallback: show boxes info in text
                    st.write(getattr(r, "boxes", "No boxes available"))
            except Exception as exc:
                st.error(f"Model inference failed: {exc}")
                result_image = dummy_inference_pil(Image.open(tfile.name).convert("RGB"))
        else:
            st.info("No model found — running demo inference.")
            result_image = dummy_inference_pil(Image.open(tfile.name).convert("RGB"))

        if result_image is not None:
            st.image(result_image, caption="Detection / Segmentation result", use_column_width=True)